{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine spec int 2006 and 2017, filter TPC-H CPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas duckdb matplotlib seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import duckdb\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "key_vendor = \"Hardware Vendor\\t\"\n",
    "key_system = \"System\"\n",
    "# SpecRate: \"Processor\", SpecSpeed: \"Processor \"\n",
    "key_processor = \"Processor \"\n",
    "\n",
    "file_combined_path = '../spec_speed/spec-cint2006-2017.csv'\n",
    "\n",
    "# Avoid data cropping when using display()\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "\n",
    "if False and os.path.exists(file_combined_path):\n",
    "    df = pd.read_csv(file_combined_path)\n",
    "else:\n",
    "    # Load data from the first CSV file\n",
    "    file1_path = '../spec_speed/spec-cint2006-results-20240730-120726.csv'\n",
    "    if os.path.exists(file1_path):\n",
    "        data1 = pd.read_csv(file1_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"The file {file1_path} does not exist.\")\n",
    "\n",
    "    # Load data from the second CSV file\n",
    "    file2_path = '../spec_speed/spec-cint2017-results-20240730-120816.csv'\n",
    "    if os.path.exists(file2_path):\n",
    "        data2 = pd.read_csv(file2_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"The file {file2_path} does not exist.\")\n",
    "\n",
    "    # Add a column to each dataframe to label the source\n",
    "    data1['Source'] = 'cint2006'\n",
    "    data2['Source'] = 'cint2017'\n",
    "    # 2006 columns: 'Result' 'Baseline'\n",
    "    # 2017 columns: 'Result' 'Baseline'\n",
    "    data1['perf'] = data1['Result']\n",
    "    data2['perf'] = data2['Result'] * 9\n",
    "    # data2[\"perf\"] = data2[\"Result\"]\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df = pd.concat([data1, data2], ignore_index=True)\n",
    "    # df = data2\n",
    "    df = df[df[\"HW Avail\"].notna()]\n",
    "    df[\"hw_avail_year\"] = df[\"HW Avail\"].str.split('-').str[1].astype(int)\n",
    "    df[\"perf_per_chip\"] = df[\"perf\"] / df[\"# Chips\"]\n",
    "    # Filter out 0 values\n",
    "    df = df[df[\"perf\"] != 0]\n",
    "    # df[\"baseline_per_core\"] = df[\"Baseline\"] / df[\"# Cores\"]\n",
    "    # Use below line to write data\n",
    "    df.to_csv(file_combined_path, index=False)\n",
    "display(df.columns)\n",
    "display(df.index)\n",
    "    \n",
    "    \n",
    "# con = duckdb.connect(\"../spec.db\")\n",
    "# con.sql(\"DROP TABLE IF EXISTS spec\")\n",
    "# con.sql(\"CREATE TABLE spec AS SELECT * FROM df\")\n",
    "# con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_df = pd.merge(data1, data2, on=['Processor ', 'Memory', '# Cores', '# Chips'], suffixes=['_2006', '_2017'])\n",
    "shared_df = shared_df[(shared_df['Result_2006'] > 0) & (shared_df['Result_2017'] > 0)]\n",
    "factor_df = shared_df['Result_2006'] / shared_df['Result_2017']\n",
    "print(shared_df['Result_2006'].describe())\n",
    "print()\n",
    "print(shared_df['Result_2017'].describe())\n",
    "print()\n",
    "print(factor_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "# display(df)\n",
    "plt.figure(figsize=(4, 2))\n",
    "# y_val = 'Baseline'\n",
    "y_val = 'perf_per_chip'\n",
    "#y_val = 'baseline_per_core'\n",
    "plt.scatter(\n",
    "    df['hw_avail_year'],\n",
    "    df[y_val],\n",
    "    marker='x')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel(y_val)\n",
    "plt.title('Performance over Years')\n",
    "plt.xticks(ticks=df['hw_avail_year'].unique(), rotation=90)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each distinct value in the \"key_vendor\" column\n",
    "value_counts = df[key_vendor].value_counts()\n",
    "\n",
    "# Create a histogram\n",
    "plt.figure(figsize=(10, 2))\n",
    "value_counts.plot(kind='bar')\n",
    "plt.title('Occurrences of Distinct Values in key_vendor Column')\n",
    "plt.xlabel('key_vendor')\n",
    "plt.ylabel('Occurrences')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Dynamic approach\n",
    "df_intel_tpc = pd.read_csv(\"../tpc_xeon_w_launch_years.csv\")\n",
    "\n",
    "def crop_model_name(name):\n",
    "    # Create a regex pattern that matches any keyword\n",
    "    pattern = \"|\".join([\"Intel Xeon\", \"CPU\", \"Bronze\", \"Gold\", \"Silver\", \"Platinum\", \"E5-\", \"E7-\"])\n",
    "    # Use regex to remove all keywords in one go\n",
    "    name = re.sub(pattern, \"\", name)\n",
    "    # if len(name) > 1 and not name[-1].isdigit():\n",
    "    #     name = name[:-1]\n",
    "    return name.strip()\n",
    "\n",
    "# print(df_intel_tpc['model'].unique())\n",
    "df_intel_tpc['short_model'] = df_intel_tpc['model'].apply(crop_model_name)\n",
    "# Remove empty ones, i.e., Intel Xeon - unclear what model was used.\n",
    "df_intel_tpc = df_intel_tpc[df_intel_tpc['short_model'] != \"\"]\n",
    "long_intel_tpc_models = df_intel_tpc['model'].unique()\n",
    "intel_tpc_models = df_intel_tpc['short_model'].unique()\n",
    "print(long_intel_tpc_models)\n",
    "print(intel_tpc_models)\n",
    "# print(len(intel_tpc_models))\n",
    "\n",
    "# only consider records with one socket\n",
    "# df = df[(df[\"# Chips\"] == 1)]\n",
    "df[\"short_model\"] = df[key_processor].apply(lambda x: next((model for model in intel_tpc_models if model in x), None))\n",
    "df = df[df[\"short_model\"].notna()]\n",
    "# Filter out rows where 'Processor' contains \"v\" but 'short_model' does not\n",
    "df = df[~((df[key_processor].str.contains('v')) & (~df['short_model'].str.contains('v')))]\n",
    "# print(df.columns)\n",
    "columns = ['Benchmark', 'Hardware Vendor\\t', 'System', '# Cores', '# Chips',\n",
    "       '# Cores Per Chip', '# Threads Per Core', 'Processor ', 'Processor MHz',\n",
    "       'Processor Characteristics', 'CPU(s) Orderable', 'Auto Parallelization',\n",
    "       'Base Pointer Size', 'Peak Pointer Size', 'HW Avail', 'SW Avail',\n",
    "       'Result', 'Baseline',\n",
    "       'Tested By', 'Test Date', 'Published', 'Updated ', 'Source', 'perf',\n",
    "       'hw_avail_year', 'perf_per_chip',\n",
    "       'short_model']\n",
    "# reduce columns\n",
    "df = df[columns]\n",
    "sources = df[\"Source\"].unique()\n",
    "# print(df_reduced[\"short_model\"].unique())\n",
    "# print(len(df_reduced[\"short_model\"].unique()))\n",
    "# print(df_reduced[\"# Chips\"].unique())\n",
    "\n",
    "\n",
    "\n",
    "# model_selection = ['Gallatin', '5160', 'X5355',\n",
    "#  '7040', '7041', '7140', '7140',\n",
    "#  '7150', 'E5320', 'E5345',\n",
    "#  'X5365', 'X5460', 'X7350',\n",
    "#  'E5420', 'X5440', 'X7460',\n",
    "#  'E5520', 'X5570', 'X5680',\n",
    "#  'X5650', 'X7560', 'X5690',\n",
    "#  '8870', '2690', '4650',\n",
    "#  '2680', '8890', '8891',\n",
    "#  '2690', '2699', '2680',\n",
    "#  '4890', '2670', '2699',\n",
    "#  '8180', '2630',\n",
    "#  '4114', '6150', '6148',\n",
    "#  '8163', '4110',\n",
    "#  '4210', '6258',\n",
    "#  '6354', '8255',\n",
    "#  '4410']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by key_processor and aggregate the metric \"perf_per_chip\"\n",
    "grouped = df.groupby([key_processor, 'short_model', 'Source'])['perf_per_chip'].agg(['mean', 'std', 'median']).reset_index()\n",
    "# display(grouped)\n",
    "\n",
    "# Renaming columns for better understanding\n",
    "grouped = grouped.rename(columns={\"mean\":'Average Perf Per Chip', 'std':'Std Dev Perf Per Chip',\"median\":'Median Perf Per Chip'})\n",
    "# grouped.columns = ['Processor', 'Average Perf Per Chip', 'Std Dev Perf Per Chip', 'Median Perf Per Chip']\n",
    "# display(grouped)\n",
    "\n",
    "# Melting the DataFrame for easier plotting\n",
    "grouped_melted = grouped.melt(id_vars=[key_processor, 'Std Dev Perf Per Chip','short_model','Source'], \n",
    "                              value_vars=['Average Perf Per Chip', 'Median Perf Per Chip'],\n",
    "                              var_name='Metric', value_name='Perf Per Chip')\n",
    "# display(grouped_melted)\n",
    "\n",
    "# Plotting using seaborn\n",
    "plt.figure(figsize=(10, 1.5))\n",
    "bar_plot = sns.barplot(x=key_processor, y='Perf Per Chip', hue='Metric', data=grouped_melted, errorbar=None)\n",
    "for i in range(len(grouped)):\n",
    "    bar_plot.errorbar(x=i-0.2, y=grouped.iloc[i]['Average Perf Per Chip'],\n",
    "                      yerr=grouped.iloc[i]['Std Dev Perf Per Chip'], fmt='none', c='red', capsize=5)\n",
    "\n",
    "plt.xlabel('Processor')\n",
    "plt.ylabel('Perf Per Chip')\n",
    "plt.title('Average and Median Perf Per Chip with Std Dev by Processor')\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend(title='Metric')\n",
    "plt.grid(axis='x')  # Add this line to enable x-axis grid lines\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_spec_perf = grouped_melted[grouped_melted[\"Metric\"].str.contains(\"Median\")]\n",
    "median_spec_perf = median_spec_perf.drop(columns=[\"Std Dev Perf Per Chip\", \"Metric\"])\n",
    "median_spec_perf.rename(columns={\"Perf Per Chip\": \"median_spec_int_speed_perf\"}, inplace=True)\n",
    "\n",
    "# display(median_spec_perf)\n",
    "\n",
    "df_combined = median_spec_perf.merge(df_intel_tpc, on=\"short_model\", how=\"left\")\n",
    "\n",
    "# display(df_combined)\n",
    "\n",
    "df_combined.to_csv(\"../spec_speed/spec-median-{}-tpc-cpus.csv\".format(\"\".join(sources)),header=True)\n",
    "# display(median_spec_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df = pd.read_csv('../tpc_xeon_perf_spec2006-2017combined.csv')\n",
    "\n",
    "# merged_df = pd.merge(df, median_spec_perf, left_on='model', right_on='Processor', how='left')\n",
    "\n",
    "# # Display the merged DataFrame\n",
    "# print(merged_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
